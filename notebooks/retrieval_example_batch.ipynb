{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import hashlib\n",
    "import PIL\n",
    "from os.path import splitext, basename, join, isfile\n",
    "from collections import defaultdict, Counter\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "\n",
    "from delf import feature_io\n",
    "sys.path.append('/home/alexandrearaujo/library/faiss/')\n",
    "import faiss\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(x):\n",
    "    \"\"\" convert array to a c-contiguous float array \"\"\"\n",
    "    return np.ascontiguousarray(x.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image to use for query\n",
    "query_filenames = [\n",
    "    '4f4b811a065c1423', # big ben\n",
    "    'b580027e974cb582', # montagne\n",
    "]\n",
    "\n",
    "# path to image use for test\n",
    "query_image_path = []\n",
    "query_feature_path = []\n",
    "for filename in query_filenames:\n",
    "    path = '/media/hdd1/kaggle/landmark-retrieval-challenge/index_256x256/{}.jpg'.format(filename)\n",
    "    query_image_path.append(path)\n",
    "    path = '/media/hdd1/kaggle/landmark-retrieval-challenge/feature_index_256x256/{}.delf'.format(filename)\n",
    "    query_feature_path.append(path)\n",
    "\n",
    "# load feature query\n",
    "n_images_query = len(query_image_path)\n",
    "loc_query = [None] * n_images_query\n",
    "desc_query = [None] * n_images_query\n",
    "n_feature_query = [None] * n_images_query\n",
    "filenames_query_ix = []\n",
    "filenames_query_ix_counter = []\n",
    "for i, path in enumerate(query_feature_path):\n",
    "    loc, _, desc, _, _ = feature_io.ReadFromFile(path)\n",
    "    loc_query[i] = loc\n",
    "    desc_query[i] = desc\n",
    "    n_feature_query[i] = desc.shape[0]\n",
    "    filenames_query_ix.extend([i] * desc.shape[0])\n",
    "    filenames_query_ix_counter.append((i, desc.shape[0]))\n",
    "    # print('query shape', i, desc.shape)\n",
    "    \n",
    "\n",
    "# images to use for indexing\n",
    "images_filenames = [\n",
    "    '4e899444d83ca6b2', # 0 big ben\n",
    "    '1b0a2ccecabea7cc', # 1 big ben\n",
    "    '693326a5738aefcd', # 2 montagne\n",
    "    '34cc88b6714be7a5', # 3 montagne with plain\n",
    "    'c1307ac9c38ecbc5', # 4 nature\n",
    "    'c2168fc9c087f805', # 5 voute\n",
    "    \n",
    "    '3f1b45fada10fa9e', # 6 distractors\n",
    "    '71ff7f6b9d3b7f08', # 7 distractors\n",
    "    'c1ac55b3f8daa72b', # 8 distractors\n",
    "    '69384190c57e1dc8', # 9 distractors\n",
    "    '601263c554e8f4d9', # 10 distractors\n",
    "    'c727199e10419a46', # 11 distractors\n",
    "    'efa8f5ec4954ea45', # 12 distractors\n",
    "]\n",
    "\n",
    "# path to image use for indexing\n",
    "index_image_path = []\n",
    "index_feature_path = []\n",
    "for filename in images_filenames:\n",
    "    path = '/media/hdd1/kaggle/landmark-retrieval-challenge/index_256x256/{}.jpg'.format(filename)\n",
    "    index_image_path.append(path)\n",
    "    path = '/media/hdd1/kaggle/landmark-retrieval-challenge/feature_index_256x256/{}.delf'.format(filename)\n",
    "    index_feature_path.append(path)\n",
    "\n",
    "# load features index\n",
    "n_images_index = len(index_image_path)\n",
    "loc_index = [None] * n_images_index\n",
    "desc_index = [None] * n_images_index\n",
    "n_feature_index = [None] * n_images_index\n",
    "filenames_index_ix = []\n",
    "filenames_index_ix_counter = {}\n",
    "filenames_index_ix_counter_cummul = {}\n",
    "filenames_index_ix_counter_cummul[0] = 0\n",
    "for i, path in enumerate(index_feature_path):\n",
    "    loc, _, desc, _, _ = feature_io.ReadFromFile(path)\n",
    "    loc_index[i] = loc\n",
    "    desc_index[i] = desc\n",
    "    n_feature_index[i] = desc.shape[0]\n",
    "    filenames_index_ix.extend([i] * desc.shape[0])\n",
    "    filenames_index_ix_counter[i] = desc.shape[0]\n",
    "    filenames_index_ix_counter_cummul[i+1] = filenames_index_ix_counter_cummul[i] + desc.shape[0]\n",
    "    # print('index shape', i, desc.shape)\n",
    "\n",
    "\n",
    "# sanitize\n",
    "desc_query = sanitize(np.concatenate(desc_query))\n",
    "desc_index = sanitize(np.concatenate(desc_index))\n",
    "print('query shape final', desc_query.shape)\n",
    "print('index shape final', desc_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the chapter about IndexIVFFlat for the setting of ncentroids. \n",
    "# The code_size is typically a power of two between 4 and 64. \n",
    "# Like for IndexPQ, d should be a multiple of m.\n",
    "\n",
    "# faiss\n",
    "d = 40 # dim of descriptors\n",
    "nlist = 2**5\n",
    "m = 8 # number of subquantizers\n",
    "quantizer = faiss.IndexFlatL2(d)  # this remains the same\n",
    "n_bits = 8 # should be 8 # bits allocated per subquantizer\n",
    "\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, n_bits)\n",
    "index.train(desc_index)\n",
    "index.add(desc_index)\n",
    "distances, index = index.search(desc_query, 60)\n",
    "# res = faiss.StandardGpuResources()\n",
    "# gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "# distances, index = gpu_index.search(desc_query, 60)\n",
    "\n",
    "\n",
    "\n",
    "# d = 40 # dim of descriptors\n",
    "# index = faiss.IndexFlatL2(d)\n",
    "# index.train(desc_index)\n",
    "# index.add(desc_index)\n",
    "# distances, index = index.search(desc_query, 60)\n",
    "\n",
    "# k = 60\n",
    "# res = faiss.StandardGpuResources()\n",
    "# gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "# distances, index = gpu_index.search(sanitize(desc_query), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove local descriptors with a distance superior to 0.8\n",
    "index[distances > 0.8] = -1\n",
    "distances = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map local descriptors index to image index\n",
    "print('mapped_index', flush=True)\n",
    "mapped_index = np.empty_like(index)\n",
    "for i, j in np.ndindex(index.shape):\n",
    "    ix = index[i, j]\n",
    "    mapped_index[i, j] = filenames_index_ix[ix] if ix != -1 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_img_by_query = {}\n",
    "start_subset, end_subset = 0, 0\n",
    "for i, (query_ix, n_descriptors) in enumerate(filenames_query_ix_counter):\n",
    "    end_subset += n_descriptors\n",
    "    subset = mapped_index[start_subset:end_subset]\n",
    "    value, count = np.unique(subset[subset != -1], return_counts=True)\n",
    "    count_img_by_query[query_ix] = Counter(dict(zip(value, count))).most_common(100)\n",
    "    start_subset += n_descriptors\n",
    "    \n",
    "count_img_by_query_final = defaultdict(list)\n",
    "start_subset, end_subset = 0, 0\n",
    "for i, (query_ix, n_descriptors_query) in enumerate(filenames_query_ix_counter):\n",
    "    # print('query_ix', query_ix, 'n_descriptors_query', n_descriptors_query)\n",
    "    \n",
    "    end_subset += n_descriptors_query\n",
    "    subset = index[start_subset:end_subset]\n",
    "    subset_mapped = mapped_index[start_subset:end_subset]\n",
    "    start_subset += n_descriptors_query\n",
    "    retrieved_images = count_img_by_query[query_ix]\n",
    "    \n",
    "    for img_ix, count in retrieved_images:\n",
    "        \n",
    "        n_descriptors_index = filenames_index_ix_counter[img_ix]\n",
    "        \n",
    "        # print('\\timg_ix', img_ix, 'n_descriptors_index', n_descriptors_index)\n",
    "    \n",
    "    \n",
    "#         ## 1 ###\n",
    "#         start = time.clock()\n",
    "#         loc_index_to_use = []\n",
    "#         loc_query_to_use = []\n",
    "#         for subset_i, line in enumerate(subset):\n",
    "#             for subset_j, value in enumerate(line):\n",
    "#                 if subset_mapped[subset_i, subset_j] != img_ix:\n",
    "#                     continue\n",
    "#                 # offset the index\n",
    "#                 value -= filenames_index_ix_counter_cummul[img_ix]\n",
    "#                 loc_query_to_use.append(loc_query[query_ix][subset_i, :])\n",
    "#                 loc_index_to_use.append(loc_index[img_ix][value, :])\n",
    "#         loc_query_to_use = np.array(loc_query_to_use)\n",
    "#         loc_index_to_use = np.array(loc_index_to_use)\n",
    "#         print('1', time.clock() - start)\n",
    "\n",
    "        \n",
    "        ## 2 ##\n",
    "        start = time.clock()\n",
    "        loc_index_to_use = []\n",
    "        loc_query_to_use = []\n",
    "        index_for_query_loc = np.arange(subset.shape[0])[:, np.newaxis].repeat(subset.shape[1], axis=1)\n",
    "        \n",
    "        cond = (subset_mapped == img_ix) & (subset != -1)\n",
    "        index_for_query_loc = index_for_query_loc[cond]\n",
    "        index_for_index_loc = subset[cond] - filenames_index_ix_counter_cummul[img_ix]\n",
    "        assert len(index_for_query_loc) == len(index_for_index_loc)\n",
    "        \n",
    "        for ix_query_loc, ix_index_loc in zip(index_for_query_loc, index_for_index_loc):\n",
    "            loc_query_to_use.append(loc_query[query_ix][ix_query_loc, :])\n",
    "            loc_index_to_use.append(loc_index[img_ix][ix_index_loc, :])\n",
    "        \n",
    "        loc_query_to_use = np.array(loc_query_to_use)\n",
    "        loc_index_to_use = np.array(loc_index_to_use)\n",
    "        print('2', time.clock() - start)\n",
    "        \n",
    "        ## 3 ##\n",
    "        start = time.clock()\n",
    "        index_for_query_loc = np.arange(subset.shape[0])[:, np.newaxis].repeat(subset.shape[1], axis=1)\n",
    "        cond = (subset_mapped == img_ix) & (subset != -1)\n",
    "        index_for_query_loc = index_for_query_loc[cond]\n",
    "        index_for_index_loc = subset[cond] - filenames_index_ix_counter_cummul[img_ix]\n",
    "        loc_query_to_use_2 = loc_query[query_ix][index_for_query_loc]\n",
    "        loc_index_to_use_2 = loc_index[img_ix][index_for_index_loc]\n",
    "        print('3', time.clock() - start)\n",
    "        \n",
    "        ## test ## \n",
    "        assert np.array_equal(loc_query_to_use, loc_query_to_use_2)\n",
    "        assert np.array_equal(loc_index_to_use, loc_index_to_use_2)\n",
    "        \n",
    "        \n",
    "        # Perform geometric verification using RANSAC.\n",
    "        _, inliers = ransac(\n",
    "          (loc_index_to_use, loc_query_to_use),\n",
    "          AffineTransform,\n",
    "          min_samples=5,\n",
    "          residual_threshold=20,\n",
    "          max_trials=2000)\n",
    "        nb_inliers = 0 if inliers is None else np.sum(inliers)\n",
    "        # print('\\t\\tnb_inliers', nb_inliers, 'count', count, '\\n')\n",
    "        if nb_inliers != 0:\n",
    "            count_img_by_query_final[query_ix].append((img_ix, nb_inliers))\n",
    "        \n",
    "for key in count_img_by_query_final.keys():\n",
    "    count_img_by_query_final[key] = sorted(count_img_by_query_final[key], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in count_img_by_query.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in count_img_by_query_final.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature locations for putative matches\n",
    "loc_index_to_use = np.array([\n",
    "  loc_index[indices[i],]\n",
    "  for i in range(n_features_query)\n",
    "  if indices[i] != -1\n",
    "])\n",
    "\n",
    "loc_query_to_use = np.array([\n",
    "  loc_query[i,]\n",
    "  for i in range(n_features_query)\n",
    "  if indices[i] != -1\n",
    "])\n",
    "print(len(loc_index_to_use), len(loc_query_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform geometric verification using RANSAC.\n",
    "_, inliers = ransac(\n",
    "  (loc_index_to_use, loc_query_to_use),\n",
    "  AffineTransform,\n",
    "  min_samples=3,\n",
    "  residual_threshold=20,\n",
    "  max_trials=1000)\n",
    "nb_inliers = 0 if inliers is None else np.sum(inliers)\n",
    "print(nb_inliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize correspondences, and save to file.\n",
    "_, ax = plt.subplots()\n",
    "img_1 = mpimg.imread(image_query_path)\n",
    "img_2 = mpimg.imread(image_index_path)\n",
    "inlier_idxs = np.nonzero(inliers)[0]\n",
    "plot_matches(\n",
    "  ax,\n",
    "  img_1,\n",
    "  img_2,\n",
    "  loc_query_to_use,\n",
    "  loc_index_to_use,\n",
    "  np.column_stack((inlier_idxs, inlier_idxs)),\n",
    "  matches_color='b')\n",
    "ax.axis('off')\n",
    "ax.set_title('DELF correspondences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nearest-neighbor matches using a KD tree.\n",
    "d1_tree = cKDTree(desc_index)\n",
    "_, indices = d1_tree.query(\n",
    "  desc_query, distance_upper_bound=0.8)\n",
    "\n",
    "print('indices', len(indices))\n",
    "\n",
    "# Select feature locations for putative matches.\n",
    "loc_index_to_use = np.array([\n",
    "  loc_index[indices[i],]\n",
    "  for i in range(n_features_query)\n",
    "  if indices[i] != n_features_index\n",
    "])\n",
    "loc_query_to_use = np.array([\n",
    "  loc_query[i,]\n",
    "  for i in range(n_features_query)\n",
    "  if indices[i] != n_features_index\n",
    "])\n",
    "\n",
    "print(len(loc_index_to_use))\n",
    "print(len(loc_query_to_use))\n",
    "\n",
    "# Perform geometric verification using RANSAC.\n",
    "_, inliers = ransac(\n",
    "  (loc_index_to_use, loc_query_to_use),\n",
    "  AffineTransform,\n",
    "  min_samples=3,\n",
    "  residual_threshold=20,\n",
    "  max_trials=1000)\n",
    "\n",
    "print('Found %d inliers' % sum(inliers))\n",
    "\n",
    "\n",
    "# Visualize correspondences, and save to file.\n",
    "_, ax = plt.subplots()\n",
    "img_1 = mpimg.imread(image_query_path)\n",
    "img_2 = mpimg.imread(image_index_path)\n",
    "inlier_idxs = np.nonzero(inliers)[0]\n",
    "plot_matches(\n",
    "  ax,\n",
    "  img_1,\n",
    "  img_2,\n",
    "  loc_query_to_use,\n",
    "  loc_index_to_use,\n",
    "  np.column_stack((inlier_idxs, inlier_idxs)),\n",
    "  matches_color='b')\n",
    "ax.axis('off')\n",
    "ax.set_title('DELF correspondences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_index_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_query_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, target_size=800):\n",
    "  def calc_by_ratio(a, b):\n",
    "    return int(a * target_size / float(b))\n",
    "\n",
    "  size = image.size\n",
    "  if size[0] < size[1]:\n",
    "    w = calc_by_ratio(size[0], size[1])\n",
    "    h = target_size\n",
    "  else:\n",
    "    w = target_size\n",
    "    h = calc_by_ratio(size[1], size[0])\n",
    "\n",
    "  # image = image.resize((w, h), Image.BILINEAR)\n",
    "  image = image.resize((w, h), Image.ANTIALIAS)\n",
    "  return image\n",
    "\n",
    "filename = splitext(basename(image_query_path))[0]\n",
    "img = Image.open(image_query_path)\n",
    "img = resize_image(img)\n",
    "out ='/media/hdd1/kaggle/landmark-retrieval-challenge/test_rescale/{}.jpg'.format(filename)\n",
    "print(out)\n",
    "# img.save(out)\n",
    "\n",
    "filename = splitext(basename(image_index_path))[0]\n",
    "img = Image.open(image_index_path)\n",
    "img = resize_image(img)\n",
    "out = '/media/hdd1/kaggle/landmark-retrieval-challenge/index_rescale/{}.jpg'.format(filename)\n",
    "print(out)\n",
    "img.save(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
