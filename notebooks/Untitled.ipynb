{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, splitext, basename\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/alexandrearaujo/libraries/faiss/')\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images = glob.glob(join('/media/hdd1/kaggle/landmark-retrieval-challenge/index_rescale/*'))\n",
    "filenames_index = set([splitext(basename(path))[0] for path in list_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images = glob.glob(join('/media/hdd1/kaggle/landmark-retrieval-challenge/feature_index_rescale_sift_pkl/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_load(path):\n",
    "  \"\"\"function to load pickle object\"\"\"\n",
    "  with open(path, 'rb') as f:\n",
    "    return pickle.load(f)\n",
    "\n",
    "def _pickle_dump(file, path):\n",
    "  \"\"\"function to dump picke object\"\"\"\n",
    "  with open(path, 'wb') as f:\n",
    "    pickle.dump(file, f, -1)\n",
    "\n",
    "def _get_new_name(path):\n",
    "  \"\"\"rename file if file already exist\"\"\"\n",
    "  i = 0\n",
    "  new_path = path\n",
    "  while isfile(new_path):\n",
    "    ext = splitext(path)[1]\n",
    "    new_path = path.replace(ext, '_{}{}'.format(i, ext))\n",
    "    i += 1\n",
    "  return new_path\n",
    "\n",
    "def pickle_dump(file, path, force=False):\n",
    "  \"\"\"dump a file without deleting an existing one\"\"\"\n",
    "  if force:\n",
    "    _pickle_dump(file, path)\n",
    "  elif not force:\n",
    "    new_path = _get_new_name(path)\n",
    "    _pickle_dump(file, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "start = datetime.now()\n",
    "for package in list_images:\n",
    "    for filename, loc, des in pickle_load(package):\n",
    "        count += 1\n",
    "        if count % 10000 == 0 and count != 0:\n",
    "            print('10000 images loaded in {}'.format((datetime.now() - start).total_seconds()))\n",
    "            start = datetime.now()\n",
    "        if filename not in filenames_index:\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../submit/9_flatindex_sift_vlad/submit_2018-04-02_07.35.11_vlad_full_index_sift_k64.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = pickle_load('../submit/9_flatindex_sift_vlad/k64_v2/filenames_index.dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index('../submit/9_flatindex_sift_vlad/k64_v2/index_full.dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map5metric(predicted, actual):\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "    metric = 0.\n",
    "    for i in range(5):\n",
    "        metric += np.sum(actual == predicted[:, i]) / (i + 1)\n",
    "    metric /= actual.shape[0]\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.array([[5, 1, 2, 3, 4], [5, 1, 2, 3, 4]])\n",
    "actual = np.array([[5], [1]]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map5metric(predicted, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random(size=(143, 10))\n",
    "b = np.random.random(size=(34, 10))\n",
    "c = np.random.random(size=(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a /= np.linalg.norm(a, ord=1, axis=1)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(a, ord=1, axis=1)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(product(np.arange(64), np.arange(64), np.arange(64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0, 10, size=(20, 10)).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.vstack((a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d -= d.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from scipy.stats import multivariate_normal\n",
    "import pickle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_load(path):\n",
    "  \"\"\"function to load pickle object\"\"\"\n",
    "  with open(path, 'rb') as f:\n",
    "    return pickle.load(f, encoding='latin1')\n",
    "\n",
    "def generate_gmm(descriptors, k):\n",
    "  # Throw away gaussians with weights that are too small:\n",
    "  em = cv2.ml.EM_create()\n",
    "  em.setClustersNumber(k)\n",
    "  em.trainEM(descriptors)\n",
    "\n",
    "  means = np.float32(em.getMeans())\n",
    "  covs = np.float32(em.getCovs())\n",
    "  weights = np.float32(em.getWeights())[0]\n",
    "\n",
    "  th = 1.0 / k\n",
    "  means   = np.array([m for w, m in zip(weights, means) if w > th])\n",
    "  covs    = np.array([c for w, c in zip(weights, covs) if w > th])\n",
    "  weights = np.array([w for w in weights if w > th])\n",
    "  return means, covs, weights\n",
    "\n",
    "def likelihood_moment(x, ytk, moment):  \n",
    "  x_moment = np.power(np.float32(x), moment) if moment > 0 else np.float32([1])\n",
    "  return x_moment * ytk\n",
    "\n",
    "def likelihood_statistics(samples, means, covs, weights):\n",
    "  gaussians = {}\n",
    "  s0, s1, s2 = defaultdict(float), defaultdict(float), defaultdict(float)\n",
    "  samples = list(zip(range(0, len(samples)), samples))\n",
    "  \n",
    "  g = [multivariate_normal(mean=means[k], cov=covs[k]) for k in range(0, len(weights)) ]\n",
    "  for index, x in samples:\n",
    "    gaussians[index] = np.array([g_k.pdf(x) for g_k in g])\n",
    "\n",
    "  for k in range(0, len(weights)):\n",
    "    s0[k], s1[k], s2[k] = 0, 0, 0\n",
    "    for index, x in samples:\n",
    "      probabilities = np.multiply(gaussians[index], weights)\n",
    "      probabilities = probabilities / np.sum(probabilities)\n",
    "      s0[k] += likelihood_moment(x, probabilities[k], 0)\n",
    "      s1[k] += likelihood_moment(x, probabilities[k], 1)\n",
    "      s2[k] += likelihood_moment(x, probabilities[k], 2)\n",
    "\n",
    "  return s0, s1, s2\n",
    "\n",
    "def fisher_vector_weights(s0, s1, s2, means, covs, w, T):\n",
    "  return np.array([((s0[k] - T * w[k]) / np.sqrt(w[k]) ) for k in range(0, len(w))])\n",
    "\n",
    "def fisher_vector_means(s0, s1, s2, means, sigma, w, T):\n",
    "  return np.array([(s1[k] - means[k] * s0[k]) / (np.sqrt(w[k] * sigma[k])) for k in range(0, len(w))])\n",
    "\n",
    "def fisher_vector_sigma(s0, s1, s2, means, sigma, w, T):\n",
    "  return np.array([(s2[k] - 2 * means[k]*s1[k]  + (means[k]*means[k] - sigma[k]) * s0[k]) / (np.sqrt(2*w[k])*sigma[k])  for k in range(0, len(w))])\n",
    "\n",
    "def normalize(fisher_vector):\n",
    "  v = np.sqrt(abs(fisher_vector)) * np.sign(fisher_vector)\n",
    "  return v / np.sqrt(np.dot(v, v))\n",
    "\n",
    "def fisher_vector(samples, means, covs, weights):\n",
    "  s0, s1, s2 =  likelihood_statistics(samples, means, covs, weights)\n",
    "  # print(s0, s1, s2)\n",
    "  covs = np.float32([np.diagonal(covs[k]) for k in range(0, covs.shape[0])])\n",
    "  a = fisher_vector_weights(s0, s1, s2, means, covs, weights, samples.shape[0])\n",
    "  b = fisher_vector_means(s0, s1, s2, means, covs, weights, samples.shape[0])\n",
    "  c = fisher_vector_sigma(s0, s1, s2, means, covs, weights, samples.shape[0])\n",
    "  fv = np.concatenate([a.flatten(), b.flatten(), c.flatten()])\n",
    "  fv = normalize(fv)\n",
    "  return fv[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dbe = pickle_load('../submit/18_dir_dbe/xindexes_dbe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pickle_load('../submit/18_dir_dbe/xqueries.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 436194,  662229,  597939, 1039291,  182534,  825411,  463045,\n",
       "       1049221,  218300, 1086121,  880338,  560583,  947842,  934271,\n",
       "        754325,  647499,  597916,  859029,  736368,   34628,  855539,\n",
       "        188085,  871438,  387865,  672381,    8721, 1046074,  840416,\n",
       "        973477,  102968,  236747,  714451,  722399,  967302,  782387,\n",
       "       1078800,  603032,  273053,  543397,  935744,  992608,   23543,\n",
       "       1038023,  818211,  235192,  674329,  276928, 1051822,  489227,\n",
       "        951975,  869879, 1038970,   40572,  275021,  360863,  581095,\n",
       "        962267,  377420,  349132,  645584,  770733,  691403, 1006152,\n",
       "        525904,  661144,  774333,   45603,  913737,  657765,  945503,\n",
       "        526532,  656701,  848527, 1007600,   89246,  336650, 1021099,\n",
       "        275593,   76985,  725735,   33446,  347490,  848594,  326557,\n",
       "        525329,  202745,  374085,  886425,  813585, 1046228,  401471,\n",
       "        821296,  427228,  881149,  199729,  518397,  815417,  774970,\n",
       "        254959,  923450])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(preds)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = pickle_load('../submit/18_dir_dbe/filenames_index.dump')\n",
    "test_filenames = pickle_load('../submit/18_dir_dbe/test_filenames.pkl')\n",
    "predicted = pickle_load('../submit/18_dir_dbe/predicted.pkl')\n",
    "\n",
    "def make_results(predicted):\n",
    "    results = {}\n",
    "    for query_ix, query_result in enumerate(predicted):\n",
    "      results[test_filenames[query_ix]] = ' '.join(\n",
    "        [train_filenames[ix] for ix in query_result if ix != -1])\n",
    "    return results\n",
    "\n",
    "results = make_results(predicted)\n",
    "\n",
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "submit['images'] = submit['id'].apply(lambda ix: results.get(ix, ''))\n",
    "submit_filename = 'submit_{}_dir_full_index_db20.csv.gz'.format(\n",
    "            datetime.now().strftime('%Y-%m-%d_%H.%M.%S'))\n",
    "submit.to_csv(submit_filename, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "size = 1\n",
    "for x in (5, ):\n",
    "    size *= x\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
