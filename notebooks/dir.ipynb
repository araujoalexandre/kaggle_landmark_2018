{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import subprocess\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('/home/alexandrearaujo/caffe/python/')\n",
    "import caffe\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage: test.py [-h] --gpu GPU --S S --L L --proto PROTO --weights WEIGHTS\n",
    "#                --dataset DATASET --dataset_name DATASET_NAME --eval_binary\n",
    "#                EVAL_BINARY --temp_dir TEMP_DIR [--multires] [--aqe AQE]\n",
    "#                [--dbe DBE]\n",
    "\n",
    "# G: gpu id\n",
    "# S: size to resize the largest side of the images to. The model is trained with S=800, but different values may work better depending on the task.\n",
    "# L: number of levels of the rigid grid. Model was trained with L=2, but different levels (e.g. L=1 or L=3) may work better on other tasks.\n",
    "# PROTO: path to the prototxt. There are two prototxts included.\n",
    "#   deploy_resnet101.prototxt relies on caffe being compiled with the normalization layer.\n",
    "#   deploy_resnet101_normpython.prototxt does not have that requirement as it relies on the python implementation, but it may be slower as it is done on the cpu and does not implement backpropagation.\n",
    "# WEIGHTS: path to the caffemodel\n",
    "# DATASET: path to the dataset, for Oxford and Paris it is the directory that contains the jpg and lab folders.\n",
    "# DATASET_NAME: either Oxford or Paris\n",
    "# EVAL_BINARY: path to the compute_ap binary provided with Oxford and Paris used to compute the ap scores\n",
    "# TEMP_DIR: a temporary directory to store features and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = glob.glob('/media/hdd1/kaggle/landmark-retrieval-challenge/test_rescale/*')\n",
    "index = glob.glob('/media/hdd1/kaggle/landmark-retrieval-challenge/index_rescale/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ImageHelper:\n",
    "    def __init__(self, S, L, means):\n",
    "        self.S = S\n",
    "        self.L = L\n",
    "        self.means = means\n",
    "\n",
    "    def prepare_image_and_grid_regions_for_network(self, fname, roi=None):\n",
    "        # Extract image, resize at desired size, and extract roi region if\n",
    "        # available. Then compute the rmac grid in the net format: ID X Y W H\n",
    "        I, im_resized = self.load_and_prepare_image(fname, roi)\n",
    "        if self.L == 0:\n",
    "            # Encode query in mac format instead of rmac, so only one region\n",
    "            # Regions are in ID X Y W H format\n",
    "            R = np.zeros((1, 5), dtype=np.float32)\n",
    "            R[0, 3] = im_resized.shape[1] - 1\n",
    "            R[0, 4] = im_resized.shape[0] - 1\n",
    "        else:\n",
    "            # Get the region coordinates and feed them to the network.\n",
    "            all_regions = []\n",
    "            all_regions.append(self.get_rmac_region_coordinates(im_resized.shape[0], im_resized.shape[1], self.L))\n",
    "            R = self.pack_regions_for_network(all_regions)\n",
    "        return I, R\n",
    "\n",
    "    def get_rmac_features(self, I, R, net):\n",
    "        net.blobs['data'].reshape(I.shape[0], 3, int(I.shape[2]), int(I.shape[3]))\n",
    "        net.blobs['data'].data[:] = I\n",
    "        net.blobs['rois'].reshape(R.shape[0], R.shape[1])\n",
    "        net.blobs['rois'].data[:] = R.astype(np.float32)\n",
    "        net.forward(end='rmac/normalized')\n",
    "        return np.squeeze(net.blobs['rmac/normalized'].data)\n",
    "\n",
    "    def load_and_prepare_image(self, fname, roi=None):\n",
    "        # Read image, get aspect ratio, and resize such as the largest side equals S\n",
    "        im = cv2.imread(fname)\n",
    "        im_size_hw = np.array(im.shape[0:2])\n",
    "        ratio = float(self.S)/np.max(im_size_hw)\n",
    "        new_size = tuple(np.round(im_size_hw * ratio).astype(np.int32))\n",
    "        im_resized = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "        # If there is a roi, adapt the roi to the new size and crop. Do not rescale\n",
    "        # the image once again\n",
    "        if roi is not None:\n",
    "            roi = np.round(roi * ratio).astype(np.int32)\n",
    "            im_resized = im_resized[roi[1]:roi[3], roi[0]:roi[2], :]\n",
    "        # Transpose for network and subtract mean\n",
    "        I = im_resized.transpose(2, 0, 1) - self.means\n",
    "        return I, im_resized\n",
    "\n",
    "    def pack_regions_for_network(self, all_regions):\n",
    "        n_regs = np.sum([len(e) for e in all_regions])\n",
    "        R = np.zeros((n_regs, 5), dtype=np.float32)\n",
    "        cnt = 0\n",
    "        # There should be a check of overflow...\n",
    "        for i, r in enumerate(all_regions):\n",
    "            try:\n",
    "                R[cnt:cnt + r.shape[0], 0] = i\n",
    "                R[cnt:cnt + r.shape[0], 1:] = r\n",
    "                cnt += r.shape[0]\n",
    "            except:\n",
    "                continue\n",
    "        assert cnt == n_regs\n",
    "        R = R[:n_regs]\n",
    "        # regs where in xywh format. R is in xyxy format, where the last coordinate is included. Therefore...\n",
    "        R[:n_regs, 3] = R[:n_regs, 1] + R[:n_regs, 3] - 1\n",
    "        R[:n_regs, 4] = R[:n_regs, 2] + R[:n_regs, 4] - 1\n",
    "        return R\n",
    "\n",
    "    def get_rmac_region_coordinates(self, H, W, L):\n",
    "        # Almost verbatim from Tolias et al Matlab implementation.\n",
    "        # Could be heavily pythonized, but really not worth it...\n",
    "        # Desired overlap of neighboring regions\n",
    "        ovr = 0.4\n",
    "        # Possible regions for the long dimension\n",
    "        steps = np.array((2, 3, 4, 5, 6, 7), dtype=np.float32)\n",
    "        w = np.minimum(H, W)\n",
    "\n",
    "        b = (np.maximum(H, W) - w) / (steps - 1)\n",
    "        # steps(idx) regions for long dimension. The +1 comes from Matlab\n",
    "        # 1-indexing...\n",
    "        idx = np.argmin(np.abs(((w**2 - w * b) / w**2) - ovr)) + 1\n",
    "\n",
    "        # Region overplus per dimension\n",
    "        Wd = 0\n",
    "        Hd = 0\n",
    "        if H < W:\n",
    "            Wd = idx\n",
    "        elif H > W:\n",
    "            Hd = idx\n",
    "\n",
    "        regions_xywh = []\n",
    "        for l in range(1, L+1):\n",
    "            wl = np.floor(2 * w / (l + 1))\n",
    "            wl2 = np.floor(wl / 2 - 1)\n",
    "            # Center coordinates\n",
    "            if l + Wd - 1 > 0:\n",
    "                b = (W - wl) / (l + Wd - 1)\n",
    "            else:\n",
    "                b = 0\n",
    "            cenW = np.floor(wl2 + b * np.arange(l - 1 + Wd + 1)) - wl2\n",
    "            # Center coordinates\n",
    "            if l + Hd - 1 > 0:\n",
    "                b = (H - wl) / (l + Hd - 1)\n",
    "            else:\n",
    "                b = 0\n",
    "            cenH = np.floor(wl2 + b * np.arange(l - 1 + Hd + 1)) - wl2\n",
    "\n",
    "            for i_ in cenH:\n",
    "                for j_ in cenW:\n",
    "                    regions_xywh.append([j_, i_, wl, wl])\n",
    "\n",
    "        # Round the regions. Careful with the borders!\n",
    "        for i in range(len(regions_xywh)):\n",
    "            for j in range(4):\n",
    "                regions_xywh[i][j] = int(round(regions_xywh[i][j]))\n",
    "            if regions_xywh[i][0] + regions_xywh[i][2] > W:\n",
    "                regions_xywh[i][0] -= ((regions_xywh[i][0] + regions_xywh[i][2]) - W)\n",
    "            if regions_xywh[i][1] + regions_xywh[i][3] > H:\n",
    "                regions_xywh[i][1] -= ((regions_xywh[i][1] + regions_xywh[i][3]) - H)\n",
    "        return np.array(regions_xywh).astype(np.float32)\n",
    "    \n",
    "class NormalizeLayer(caffe.Layer):\n",
    "    def setup(self, bottom, top):\n",
    "        assert len(bottom) == 1, 'This layer can only have one bottom'\n",
    "        assert len(top) == 1, 'This layer can only have one top'\n",
    "        self.eps = 1e-8\n",
    "\n",
    "    def reshape(self, bottom, top):\n",
    "        top[0].reshape(*bottom[0].data.shape)\n",
    "\n",
    "    def forward(self, bottom, top):\n",
    "        top[0].data[:] = bottom[0].data / np.expand_dims(self.eps + np.sqrt((bottom[0].data ** 2).sum(axis=1)), axis=1)\n",
    "\n",
    "    def backward(self, top, propagate_down, bottom):\n",
    "        raise NotImplementedError(\"Backward pass not supported with this implementation\")\n",
    "\n",
    "\n",
    "class AggregateLayer(caffe.Layer):\n",
    "    def setup(self, bottom, top):\n",
    "        assert len(bottom) == 1, 'This layer can only have one bottom'\n",
    "        assert len(top) == 1, 'This layer can only have one top'\n",
    "\n",
    "    def reshape(self, bottom, top):\n",
    "        tmp_shape = list(bottom[0].data.shape)\n",
    "        tmp_shape[0] = 1\n",
    "        top[0].reshape(*tmp_shape)\n",
    "\n",
    "    def forward(self, bottom, top):\n",
    "        top[0].data[:] = bottom[0].data.sum(axis=0)\n",
    "\n",
    "    def backward(self, top, propagate_down, bottom):\n",
    "        raise NotImplementedError(\"Backward pass not supported with this implementation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 512\n",
    "L = 2\n",
    "means = np.array([103.93900299,  116.77899933,  123.68000031], dtype=np.float32)[None, :, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_helper = ImageHelper(S, L, means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto  = '../submit/16_dir_desc/deploy_resnet101_normpython.prototxt'\n",
    "weights  = '../submit/16_dir_desc/model.caffemodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure caffe and load the network\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Net(proto, weights, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I, R = image_helper.prepare_image_and_grid_regions_for_network(index[2], roi=None)\n",
    "R = R.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(I.shape)\n",
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.blobs['data'].reshape(I.shape[0], 3, int(I.shape[2]), int(I.shape[3]))\n",
    "net.blobs['data'].data[:] = I\n",
    "net.blobs['rois'].reshape(R.shape[0], R.shape[1])\n",
    "net.blobs['rois'].data[:] = R.astype(np.float32)\n",
    "net.forward(end='rmac/normalized')\n",
    "res = net.blobs['rmac/normalized'].data\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.blobs['data'].data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "net.blobs['data'].reshape(batch_size, 3, 512, 384)\n",
    "net.blobs['rois'].reshape(batch_size, R.shape[0], R.shape[1])\n",
    "\n",
    "shape = (1, 3, 512, 384)\n",
    "\n",
    "for i in range(batch_size):\n",
    "\n",
    "    I, R = image_helper.prepare_image_and_grid_regions_for_network(index[i], roi=None)\n",
    "    R = R.astype('float32')\n",
    "    if I.shape != shape:\n",
    "        I = I.transpose(0, 1, 3, 2)\n",
    "    print(I.shape)\n",
    "    \n",
    "    net.blobs['data'].data[i] = I\n",
    "    net.blobs['rois'].data[i] = R\n",
    "\n",
    "net.forward(end='pooled_rois/pca/normalized')\n",
    "res_new = net.blobs['pooled_rois/pca/normalized'].data\n",
    "print(res_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_queries = np.vstack([\n",
    "    np.vstack((features_queries[i], features_dataset[idx[i, :args.aqe]])).mean(axis=0) for i in range(len(features_queries))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features_queries)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = image_helper.get_rmac_features(I, R, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fn(example):\n",
    "  \"Parse TFExample records and perform simple data augmentation.\"\n",
    "  example_fmt = {\n",
    "    \"image\": tf.FixedLengthFeature((), tf.string, \"\"),\n",
    "    \"label\": tf.FixedLengthFeature((), tf.int64, -1)\n",
    "  }\n",
    "  parsed = tf.parse_single_example(example, example_fmt)\n",
    "  image = tf.image.decode_image(parsed[\"image\"])\n",
    "  image = _augment_helper(image)  # augments image using slice, reshape, resize_bilinear\n",
    "  return image, parsed[\"label\"]\n",
    "\n",
    "def input_fn():\n",
    "  files = tf.data.Dataset.list_files(\"/path/to/dataset/train-*.tfrecord\")\n",
    "  dataset = files.interleave(tf.data.TFRecordDataset)\n",
    "  dataset = dataset.shuffle(buffer_size=FLAGS.shuffle_buffer_size)\n",
    "  dataset = dataset.map(map_func=parse_fn)\n",
    "  dataset = dataset.batch(batch_size=FLAGS.batch_size)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "\n",
    "\n",
    "import glob\n",
    "index = glob.glob('/media/hdd1/kaggle/landmark-retrieval-challenge/index_rescale/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def process(image):\n",
    "    print(image.shape)\n",
    "    return image.mean()\n",
    "\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(index)\n",
    "reader = tf.WholeFileReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "img = tf.image.decode_jpeg(value)\n",
    "\n",
    "a = tf.placeholder(np.float32)\n",
    "\n",
    "out = tf.py_func(process, img, [a])\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "  sess.run(init_op)\n",
    "  coord = tf.train.Coordinator()\n",
    "  threads = tf.train.start_queue_runners(coord=coord)\n",
    "  image = out.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in itertools.repeat(None, 15):\n",
    "    x = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
